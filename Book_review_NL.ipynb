{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Book review NL",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac9d9a6a8d93423a83da8c43a1537c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8109da15b8004973b01254b7394d50f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_306ef493b80c4d1fa9225a7676f4984c",
              "IPY_MODEL_33675a73931f42e8b121212ce68a44c4"
            ]
          }
        },
        "8109da15b8004973b01254b7394d50f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "306ef493b80c4d1fa9225a7676f4984c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff9abf65a8bb402bb62f7db9c7ec802b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df595f9d3e844c2c9f23afe6f3aa3969"
          }
        },
        "33675a73931f42e8b121212ce68a44c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f6f900bbaeea42d6b6cbf6e032b65793",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:34&lt;00:00, 18.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e1108b234d5433ab4e55d13f664a13e"
          }
        },
        "ff9abf65a8bb402bb62f7db9c7ec802b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df595f9d3e844c2c9f23afe6f3aa3969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6f900bbaeea42d6b6cbf6e032b65793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e1108b234d5433ab4e55d13f664a13e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88bb80d3fb784214b48e629084672e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78698aa235114fddb67fbd3bb86dbc0b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_15517c9fa9ca4ab7ae0d87a5a53d92db",
              "IPY_MODEL_b8f940367ed44911974216e111cba08d"
            ]
          }
        },
        "78698aa235114fddb67fbd3bb86dbc0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15517c9fa9ca4ab7ae0d87a5a53d92db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f3500d7798e44b09a028414665b60afd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 999358484,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 999358484,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4974f61951a849ae9637b1ba718246f2"
          }
        },
        "b8f940367ed44911974216e111cba08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_990f155436994c3d8b43eb6fae43eacf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 999M/999M [00:22&lt;00:00, 43.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d08de188c97f430bbc637fa5149c0004"
          }
        },
        "f3500d7798e44b09a028414665b60afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4974f61951a849ae9637b1ba718246f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "990f155436994c3d8b43eb6fae43eacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d08de188c97f430bbc637fa5149c0004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spdrnl/bert_multilingual/blob/master/Book_review_NL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj7QV6PWAz5b",
        "colab_type": "text"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbT8EGWRWoNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3b45eef9-76c6-40e9-8d57-6abba3b16e0b"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 8.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 25.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 56.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 49.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7TogsID0Kk7",
        "colab_type": "text"
      },
      "source": [
        "# Check the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHrLCqXr_n3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4ede6dc-bbee-4456-a784-9b913ee427ff"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhYJ2VAqVYMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "715b797f-b05a-4c1f-912c-3651d29d842d"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep  8 11:11:12 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    29W /  70W |    227MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwJ8cEE90QP_",
        "colab_type": "text"
      },
      "source": [
        "# Download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrxqncwoSipi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "5e42e8c1-2243-4d5e-81e6-8551aa0242ef"
      },
      "source": [
        "! wget https://github.com/benjaminvdb/110kDBRD/releases/download/v2.0/110kDBRD_v2.tgz\n",
        "! tar -zxf 110kDBRD_v2.tgz 110kDBRD/train\n",
        "! tar -zxf 110kDBRD_v2.tgz 110kDBRD/test\n",
        "! ls 110kDBRD"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-08 13:04:20--  https://github.com/benjaminvdb/110kDBRD/releases/download/v2.0/110kDBRD_v2.tgz\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/168819565/a09c2700-96a1-11e9-9310-a218631917bf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200908%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200908T130420Z&X-Amz-Expires=300&X-Amz-Signature=54dbd116979f7a3814100448fc6b6bec4409ef09046bffff279650bb9e850396&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=168819565&response-content-disposition=attachment%3B%20filename%3D110kDBRD_v2.tgz&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-09-08 13:04:20--  https://github-production-release-asset-2e65be.s3.amazonaws.com/168819565/a09c2700-96a1-11e9-9310-a218631917bf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200908%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200908T130420Z&X-Amz-Expires=300&X-Amz-Signature=54dbd116979f7a3814100448fc6b6bec4409ef09046bffff279650bb9e850396&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=168819565&response-content-disposition=attachment%3B%20filename%3D110kDBRD_v2.tgz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.132.99\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.132.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79052852 (75M) [application/octet-stream]\n",
            "Saving to: â€˜110kDBRD_v2.tgzâ€™\n",
            "\n",
            "110kDBRD_v2.tgz     100%[===================>]  75.39M  22.7MB/s    in 3.3s    \n",
            "\n",
            "2020-09-08 13:04:24 (22.7 MB/s) - â€˜110kDBRD_v2.tgzâ€™ saved [79052852/79052852]\n",
            "\n",
            "test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGzS2OQU2COj",
        "colab_type": "text"
      },
      "source": [
        "# Read and split the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPqOaaAhZfNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "ce74acba-ce53-4b27-95a2-3f587d947bf6"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "def read_file(file_name):\n",
        "  with open(file_name) as f:\n",
        "    text = f.read()\n",
        "  return text\n",
        "\n",
        "def get_file_contents(base_dir, train_test, label):\n",
        "  filter = base_dir + '/' + train_test + '/' + label + '/*.txt'\n",
        "  contents = [read_file(file_name) for file_name in glob.glob(filter)]\n",
        "  return contents\n",
        "\n",
        "def get_data(base_dir, train_test):\n",
        "  txt_pos = get_file_contents(base_dir, train_test, 'pos')\n",
        "  txt_neg = get_file_contents(base_dir, train_test, 'neg')\n",
        "  txt = txt_pos + txt_neg\n",
        "  n_pos, n_neg = len(txt_pos), len(txt_neg)\n",
        "  labels = np.hstack([np.ones(n_pos), np.zeros(n_neg)])\n",
        "  return txt, labels, n_pos, n_neg\n",
        "\n",
        "base_dir = '110kDBRD'\n",
        "\n",
        "data_txt, data_labels, n_pos, n_neg = get_data(base_dir, 'train')\n",
        "test_txt, test_labels, n_t_pos, n_t_neg= get_data(base_dir, 'test')\n",
        "\n",
        "print(f\"The number of train samples is {len(data_labels)}, {n_pos}+/{n_neg}-\")\n",
        "print(f\"The number of test samples is {len(test_labels)}, {n_t_pos}+/{n_t_neg}-\")\n",
        "print(f\"Example text: {data_txt[0]}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of train samples is 20028, 10014+/10014-\n",
            "The number of test samples is 2224, 1112+/1112-\n",
            "Example text: Siegfried Lenz was een geweldig schrijver. In een paar pennestreken wist hij een sfeer neer te zetten en een hele wereld op te roepen. Zo ook in dit boek dat over een ouder wordende duiker in het Duitsland van net na de Tweede Wereldoorlog gaat. Het is een novelle maar na het lezen heb ik het idee dat ik een roman van over de 500 pagina's gelezen heb. Dat is de kracht van Lenz. Een boek waar je niet echt vrolijker van wordt maar wel een aanrader.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojAVc8iSVuBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_txt, val_txt, train_labels, val_labels = train_test_split(data_txt, data_labels, test_size=0.2, shuffle=True, random_state=84)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd-3uiY4AcT9",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZM5WFrEBH1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "model_name = 'bert-base-multilingual-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPChKGc2bVor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9972b898-b69e-4659-90a3-711796973625"
      },
      "source": [
        "max_len = 0\n",
        "for txts in [train_txt, val_txt, test_txt]:\n",
        "  for txt in txts:\n",
        "    tokenized = tokenizer.tokenize(txt)\n",
        "    max_len = max(max_len, len(tokenized))\n",
        "\n",
        "print(f\"The maximum length in tokens is {max_len}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maximum length in tokens is 5814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hlqv5myOTKmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6ff99e7e-1558-4692-a166-bc44da54b4f0"
      },
      "source": [
        "vocabulary = tokenizer.get_vocab()\n",
        "print(list(vocabulary.keys())[:125])\n",
        "print(list(vocabulary.keys())[1000:1010])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[PAD]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]', '[unused50]', '[unused51]', '[unused52]', '[unused53]', '[unused54]', '[unused55]', '[unused56]', '[unused57]', '[unused58]', '[unused59]', '[unused60]', '[unused61]', '[unused62]', '[unused63]', '[unused64]', '[unused65]', '[unused66]', '[unused67]', '[unused68]', '[unused69]', '[unused70]', '[unused71]', '[unused72]', '[unused73]', '[unused74]', '[unused75]', '[unused76]', '[unused77]', '[unused78]', '[unused79]', '[unused80]', '[unused81]', '[unused82]', '[unused83]', '[unused84]', '[unused85]', '[unused86]', '[unused87]', '[unused88]', '[unused89]', '[unused90]', '[unused91]', '[unused92]', '[unused93]', '[unused94]', '[unused95]', '[unused96]', '[unused97]', '[unused98]', '[unused99]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '<S>', '<T>', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3']\n",
            "['à´¿', 'àµ€', 'àµ†', 'àµ‡', 'àµˆ', 'àµ—', 'àµ§', 'àµ¨', 'àµº', 'àµ»']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipEUwB32-z8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eeba5358-e366-4eb7-af4f-346f19df1559"
      },
      "source": [
        "tokenizer.get_vocab()['[CLS]']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWJEE1roXHY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e98d400-4e5c-4600-cb27-baf79182f6fc"
      },
      "source": [
        "tokenizer.get_vocab()['idee']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij9VS8M9xskl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a590023b-e0e7-4c5d-b84a-972212e04c2e"
      },
      "source": [
        "tokenizer.get_vocab()['huis']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMZXWx_t0m8A",
        "colab_type": "text"
      },
      "source": [
        "# Encode the data to word pieces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9mf_oaKbLUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ac715800-ac3d-4d74-9e9c-2957abe14277"
      },
      "source": [
        "def encode_text(txt, max_len):\n",
        "  return tokenizer.batch_encode_plus(txt,\n",
        "                        add_special_tokens = True, \n",
        "                        max_length = max_len, \n",
        "                        pad_to_max_length = True, \n",
        "                        return_attention_mask = True, \n",
        "                        truncation = True)\n",
        "max_len = 512\n",
        "train_encoded = encode_text(train_txt, max_len)\n",
        "val_encoded = encode_text(val_txt, max_len)\n",
        "test_encoded = encode_text(test_txt, max_len)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJiT6mai2Xpl",
        "colab_type": "text"
      },
      "source": [
        "# Create datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l-h6MSlo5Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_example_to_dict(input_ids, attention_masks, token_type_ids, labels):\n",
        "  return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"token_type_ids\": token_type_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "  }, labels\n",
        "\n",
        "def to_dataset(encoded_txt, labels):\n",
        "  return tf.data.Dataset.from_tensor_slices(((encoded_txt['input_ids'],\n",
        "                                            encoded_txt['attention_mask'],\n",
        "                                            encoded_txt['token_type_ids']),\n",
        "                                            labels))#.map(map_example_to_dict)\n",
        "\n",
        "train_dataset = to_dataset(train_encoded, train_labels)\n",
        "val_dataset = to_dataset(val_encoded, val_labels)\n",
        "test_dataset = to_dataset(test_encoded, test_labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGf3e_S_OYmk",
        "colab_type": "text"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nS7hxpUOqm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446,
          "referenced_widgets": [
            "ac9d9a6a8d93423a83da8c43a1537c52",
            "8109da15b8004973b01254b7394d50f1",
            "306ef493b80c4d1fa9225a7676f4984c",
            "33675a73931f42e8b121212ce68a44c4",
            "ff9abf65a8bb402bb62f7db9c7ec802b",
            "df595f9d3e844c2c9f23afe6f3aa3969",
            "f6f900bbaeea42d6b6cbf6e032b65793",
            "0e1108b234d5433ab4e55d13f664a13e",
            "88bb80d3fb784214b48e629084672e2a",
            "78698aa235114fddb67fbd3bb86dbc0b",
            "15517c9fa9ca4ab7ae0d87a5a53d92db",
            "b8f940367ed44911974216e111cba08d",
            "f3500d7798e44b09a028414665b60afd",
            "4974f61951a849ae9637b1ba718246f2",
            "990f155436994c3d8b43eb6fae43eacf",
            "d08de188c97f430bbc637fa5149c0004"
          ]
        },
        "outputId": "bad70b37-eb61-47a8-f3ce-43b8530600f7"
      },
      "source": [
        "from transformers import BertConfig, TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "def get_transfer_model(model_name, learning_rate):\n",
        "  model = TFBertForSequenceClassification.from_pretrained(model_name)\n",
        "  model.num_labels=2\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "  #model.get_layer('bert').trainable = False\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "  return model\n",
        "\n",
        "# def get_transfer_model(model_name, learning_rate):\n",
        "#   bert_model = TFBertForSequenceClassification.from_pretrained(model_name)\n",
        "#   bert = bert_model.get_layer('bert')\n",
        "  \n",
        "#   id_input_layer = keras.layers.Input(shape = (max_len,), dtype='int32')\n",
        "#   attention_input_layer = keras.layers.Input(shape = (max_len,), dtype='int32')\n",
        "#   token_type_input_layer = keras.layers.Input(shape = (max_len,), dtype='int32')\n",
        "  \n",
        "#   bert_layer = bert([id_input_layer, attention_input_layer, token_type_input_layer])[1]\n",
        "#   output_layer = keras.layers.Dense(2, activation=\"softmax\")(bert_layer) \n",
        "#   model = keras.Model(inputs=[id_input_layer, attention_input_layer, token_type_input_layer], outputs=output_layer)\n",
        "\n",
        "#   model.get_layer('bert').trainable = False\n",
        "\n",
        "#   optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "#   loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#   metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "#   model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "#   return model\n",
        "\n",
        "learning_rate = 1e-5\n",
        "model = get_transfer_model(model_name, learning_rate)\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac9d9a6a8d93423a83da8c43a1537c52",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88bb80d3fb784214b48e629084672e2a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=999358484.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['dropout_37', 'classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  167356416 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 167,357,954\n",
            "Trainable params: 167,357,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81vtl50PSfxD",
        "colab_type": "text"
      },
      "source": [
        "# Train model with transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUf0ghBJi6P9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "9b5f62db-0050-47cd-b309-d1451476b7da"
      },
      "source": [
        "batch_size = 8\n",
        "learning_rate = 1e-5\n",
        "number_of_epochs = 200\n",
        "histories = []\n",
        "results = []\n",
        "sample_sizes = [100, 250, 500, 1000, 2500, 5000, 10000, len(train_labels)]\n",
        "sample_sizes = [len(train_labels)]\n",
        "for sample_size in sample_sizes:\n",
        "  model = get_transfer_model(model_name, learning_rate)\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, restore_best_weights=True)\n",
        "  history = model.fit(train_dataset.take(sample_size).shuffle(1000).batch(batch_size), \n",
        "                      epochs=number_of_epochs, \n",
        "                      validation_data=val_dataset.batch(batch_size),\n",
        "                      callbacks = [early_stopping])\n",
        "  result = model.evaluate(test_dataset.batch(batch_size))\n",
        "  print(f\"At sample size {sample_size} test evaluation is {result}\")\n",
        "  histories.append(history)\n",
        "  results.append((sample_size, result))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['dropout_113', 'classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "2003/2003 [==============================] - 1252s 625ms/step - loss: 0.3671 - accuracy: 0.8304 - val_loss: 0.2899 - val_accuracy: 0.8814\n",
            "Epoch 2/200\n",
            "2003/2003 [==============================] - 1248s 623ms/step - loss: 0.2164 - accuracy: 0.9115 - val_loss: 0.2497 - val_accuracy: 0.9031\n",
            "Epoch 3/200\n",
            "2003/2003 [==============================] - 1248s 623ms/step - loss: 0.1436 - accuracy: 0.9430 - val_loss: 0.2838 - val_accuracy: 0.8997\n",
            "Epoch 4/200\n",
            "2003/2003 [==============================] - 1248s 623ms/step - loss: 0.0933 - accuracy: 0.9643 - val_loss: 0.3596 - val_accuracy: 0.9069\n",
            "278/278 [==============================] - 54s 193ms/step - loss: 0.2568 - accuracy: 0.8961\n",
            "At sample size 16022 test evaluation is [0.2568327486515045, 0.8961330652236938]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6SpaO0pqJsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}